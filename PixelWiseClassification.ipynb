{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pixel Wise Classification of liver slices\n",
    "\n",
    "To classify every pixel in a given image, the classification network has to be \"rolled\" over the image with a stride 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "import skimage.io as sio # for reading an image\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "%matplotlib inline\n",
    "plt.set_cmap('gray')\n",
    "\n",
    "# importing torch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# generic libraries\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the image\n",
    "\n",
    "image `liver_slice_4x.png` is padded by `[32, 32]`. Therefore, initial image size is `192x192` after `128x128` is padded with `32x32` on all sides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = sio.imread('test_images/liver_slice_4x.png')\n",
    "x = x / 255 # normalize image to 0 to 1\n",
    "plt.imshow(x)\n",
    "print('Image shape: ' + str(x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the classification network\n",
    "\n",
    "``` Conv1 -> Conv2 -> MaxPool2D -> Conv3 -> Conv4 -> MaxPool2D -> FC1 -> FC2 -> LogSoftMax```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(1, 32, kernel_size=3), nn.BatchNorm2d(32))\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(32, 64, kernel_size=3), nn.BatchNorm2d(64))\n",
    "        \n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(64, 128, kernel_size=3), nn.BatchNorm2d(128))\n",
    "        self.conv4 = nn.Sequential(nn.Conv2d(128, 128, kernel_size=3), nn.BatchNorm2d(128))\n",
    "        \n",
    "        self.fc1 = nn.Sequential(nn.Linear(3200, 500), nn.BatchNorm1d(500))\n",
    "        self.fc2 = nn.Sequential(nn.Linear(500, 2), nn.BatchNorm1d(2))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = x.view(x.size(0), -1) # Rasterizes tensor by preserving 0th dimension\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the checkpoint for the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Net().float()\n",
    "checkpoint = torch.load('pretrained_models/pwcNetwork_cpu.tar')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model = model.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATCH_SIZE = [32, 32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling the network on the image\n",
    "\n",
    "Roll the network / raster-scan the image from top-left to bottom-right.\n",
    "\n",
    "To counter the reduction in image-size because of not processing the edge pixels, the image is padded with zeros.\n",
    "\n",
    "Hence, the starting and ending point of this rolling for every row is `patch_size` and `image_shape - patch_size`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "out_image = []\n",
    "\n",
    "start_y, end_y = PATCH_SIZE[0], x.shape[0] - PATCH_SIZE[0]\n",
    "start_x, end_x = PATCH_SIZE[1], x.shape[1] - PATCH_SIZE[1]\n",
    "\n",
    "for i in range(start_y, end_y):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for j in range(start_x, end_x):\n",
    "        \n",
    "        center = [i, j]\n",
    "        \n",
    "        # extract patch\n",
    "        patch = x[center[0]-PATCH_SIZE[0]//2 : center[0]+PATCH_SIZE[0]//2,\n",
    "                  center[1]-PATCH_SIZE[1]//2 : center[1]+PATCH_SIZE[1]//2]\n",
    "        \n",
    "        # pre-process patch for forward pass\n",
    "        patch = patch.reshape(1, 1,PATCH_SIZE[0], PATCH_SIZE[1])\n",
    "        patch = torch.from_numpy(patch)\n",
    "        patch = Variable(patch, volatile=True)\n",
    "        patch = patch.float()\n",
    "        \n",
    "        # predict with model\n",
    "        out = model.forward(patch)\n",
    "        \n",
    "        # convert Variables into NumPy arrays\n",
    "        out = out.data.numpy()\n",
    "        out_image.append(out)\n",
    "        \n",
    "    print('Rows processed: ' + str(i+1 - PATCH_SIZE[0]) + ' Time taken: ' + str(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post process the output image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_image = np.array(out_image) # Convert list into array\n",
    "out_image = np.exp(out_image) # Torch network gives out log softmax outputs. Nullify log by applying exp operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output tensor is `[N, 1, 2]` in shape where `N` is the number of patches processed during raster scanning a.k.a \"rolling\".\n",
    "\n",
    "`np.argmax` on the `2`nd dimension will return binary values for every patch\n",
    "\n",
    "Once all the patches are binarized, the tensor is reshaped into a `128x128` 2D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_output = np.argmax(out_image, axis=2).reshape(128, 128) # Take argmax along probability dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot the predicted image\n",
    "plt.imshow(final_output)\n",
    "\n",
    "# plot the original image\n",
    "plt.figure()\n",
    "plt.imshow(x[PATCH_SIZE[0] : x.shape[0]-PATCH_SIZE[0],\n",
    "             PATCH_SIZE[1] : x.shape[1]-PATCH_SIZE[1]]) # crop the original image by the padded amount"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
